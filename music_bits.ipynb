{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "068698ab-fd8e-4915-b208-58b76dac00d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ok\\anaconda3\\envs\\Environment_1\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import json\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import note_seq\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ff3575e-ce82-44c2-9d52-89c6759ad6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"clzg6zq880004jy0cykcuqehm\"\n",
    "BASE_URL = 'https://api.musicfy.lol/v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96f7349-e134-4bcc-99cf-f828f871e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to generate music from text\n",
    "def generate_music_from_text(text_description, genre):\n",
    "    url = f\"{BASE_URL}/generate-music\"\n",
    "    instruments = []\n",
    "    all_midis = []\n",
    "\n",
    "    pop = (\"piano\", \"violin\", \"guitar\", \"synthesizer\", \"drums\", \"flute\", \"vocals\")\n",
    "    jazz = (\"saxophone\", \"trumpet\", \"trombone\", \"piano\", \"bass\", \"drums\", \"guitar\")\n",
    "    hip_hop = (\"drum machine\", \"keyboard\", \"piano\", \"turntable\", \"sampler\", \"bass\", \"guitar\")\n",
    "    gospel = (\"piano\", \"Hammond organ\", \"tambourines\", \"drums\", \"bass guitar\", \"keyboard\", \"electric guitar\")\n",
    "    \n",
    "    \n",
    "    if genre == \"pop\":\n",
    "        instruments = pop\n",
    "    elif genre == \"jazz\":\n",
    "        instruments = jazz\n",
    "    elif genre == \"hip-hop\":\n",
    "        instruments = hip_hop\n",
    "    elif genre == \"gospel\":\n",
    "        instruments = gospel\n",
    "    else:\n",
    "        print(\"Sorry, selected genre not configured yet!!\")\n",
    "      \n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_KEY}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    for item in instruments:\n",
    "        data = {\n",
    "            'prompt': item,\n",
    "            'text': text_description,\n",
    "            'genre': genre\n",
    "        }\n",
    "\n",
    "        response = requests.request(\"POST\",url, headers=headers, json=data).text\n",
    "\n",
    "        #Using json formatting to extract the html link from the response of the request\n",
    "        data = json.loads(response)\n",
    "        file_url = data[0]['file_url']\n",
    "        \n",
    "        all_midis.append(file_url)\n",
    "        \n",
    "    #print(response.text)\n",
    "    return all_midis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36322b74-4583-4b5b-ae49-9bfb3929d8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85417591-4a9f-48e5-a6aa-ad89631cda88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_wav_files(links):\n",
    "    wav_files = []\n",
    "    for index, link in enumerate(links):\n",
    "        try:\n",
    "            response = requests.get(link)\n",
    "            response.raise_for_status()  # Check if the request was successful\n",
    "\n",
    "            parsed_url = urlparse(link)\n",
    "            file_name = os.path.basename(parsed_url.path)\n",
    "            file_extension = os.path.splitext(file_name)[1]\n",
    "            \n",
    "            if not file_extension:\n",
    "                file_extension = '.wav'\n",
    "                \n",
    "            filename = f'wave_{index}{file_extension}'\n",
    "\n",
    "            with open(filename, 'wb') as midi_file:\n",
    "                midi_file.write(response.content)\n",
    "            wav_files.append(filename)\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to download {link}: {e}\")\n",
    "    return wav_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a951a892-ede4-4746-b565-4a60c40d7b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5a2ea8-126a-4c66-a877-cdaf6f3e895e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d50514ea-cddf-44cc-a65c-afd9e973e1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport tensorflow as tf\\n\\nimport magenta.music as mm\\nfrom magenta.models.music_vae import TrainedModel\\nfrom magenta.models.music_vae.configs import CONFIG_MAP\\nfrom magenta.models.onsets_frames_transcription import configs, onsets_frames_transcription_transcribe, data\\n\\nfrom note_seq.protobuf import music_pb2\\nfrom note_seq.sequences_lib import concatenate_sequences\\nfrom pydub import AudioSegment\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "import magenta.music as mm\n",
    "from magenta.models.music_vae import TrainedModel\n",
    "from magenta.models.music_vae.configs import CONFIG_MAP\n",
    "from magenta.models.onsets_frames_transcription import configs, onsets_frames_transcription_transcribe, data\n",
    "\n",
    "from note_seq.protobuf import music_pb2\n",
    "from note_seq.sequences_lib import concatenate_sequences\n",
    "from pydub import AudioSegment\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0152c6-15a9-47e6-a2de-7f018ecc1ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec476cac-c5fb-4b41-8cdb-74256c319ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34370ed8-366f-4095-8854-37107234c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def blend_wav_files(wav_paths, output_path):\n",
    "    valid_wavs = []\n",
    "    \n",
    "    for path in wav_paths:\n",
    "        try:\n",
    "            # Try loading the WAV file to ensure it is valid\n",
    "            wav, sr = librosa.load(path, sr=None)\n",
    "            valid_wavs.append((wav, sr))\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {path}: {e}\")\n",
    "    \n",
    "    if not valid_wavs:\n",
    "        print(\"No valid WAV files to blend.\")\n",
    "        return\n",
    "    \n",
    "    # Find the minimum length to avoid issues with different lengths\n",
    "    min_length = min([len(wav[0]) for wav in valid_wavs])\n",
    "    \n",
    "    # Truncate all wav files to the same length\n",
    "    wavs = [wav[0][:min_length] for wav in valid_wavs]\n",
    "    \n",
    "    # Stack and average the wav files to blend them\n",
    "    blended_wav = np.mean(wavs, axis=0)\n",
    "\n",
    "    # Delete the content of the output file if it exists\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Output file {output_path} already exists and will be replaced.\")\n",
    "        os.remove(output_path)\n",
    "    else:\n",
    "        print(f\"Output file {output_path} does not exist. Creating it now.\")\n",
    "    \n",
    "    # Save the blended wav file\n",
    "    sf.write(output_path, blended_wav, valid_wavs[0][1])\n",
    "    print(f\"Blended WAV file saved as {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02485190-9846-4696-ac38-8cb0d7fadf96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddcd0061-36fb-4db3-87dc-aee0debe9dff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Describe the type of beat you want to create:  jazz\n",
      "Select a genre:  jazz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file final_beat.wav already exists and will be replaced.\n",
      "Blended WAV file saved as final_beat.wav\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    text_description = input(\"Describe the type of beat you want to create: \").lower()\n",
    "    genre = input(\"Select a genre: \").lower()\n",
    "    \n",
    "    # Output file name\n",
    "    output_file = 'final_beat.wav'\n",
    "    try:\n",
    "        result = generate_music_from_text(text_description, genre)\n",
    "        print(\"Music generated successfully!\")\n",
    "\n",
    "        #for i, items in enumerate(result):\n",
    "            #print(f'item {i}, download: {items}')\n",
    "\n",
    "        downloaded_files = download_wav_files(result)\n",
    "        print(f\"Downloaded files: {downloaded_files}\")\n",
    "\n",
    "        final_output = blend_wav_files(downloaded_files, output_file)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044963a7-23c3-4ead-8659-65fcf0b6b05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02d870e-c28c-4f99-ab6c-0a290d91e9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54dc796f-e66c-4982-8c83-48e82f99366e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Converting wav files to midi files\\nCHECKPOINT_PATH = \"../maestro_checkpoint/model.ckpt\"\\n\\ndef load_model():\\n    model_config = configs.CONFIG_MAP[\\'onsets_frames\\']\\n    hparams = model_config.hparams\\n    hparams.use_cudnn = tf.test.is_gpu_available()\\n    return onsets_frames_transcription_transcribe.run(model_config, CHECKPOINT_PATH)\\n\\n\\ndef transcribe_wav_to_midi(wav_path):\\n    model = load_model()\\n    midi_files =[]\\n    for index, item in enumerate(wav_path):\\n        midi_path = f\\'midi_{index}.mid\\'\\n        \\n        samples = note_seq.audio_io.wav_data_to_samples(item, sample_rate=16000)\\n        input_tensors = data.classify_audio_to_input_tensors(samples, hparams)\\n        predictions = model.predict(input_tensors, input_tensors)\\n        sequence = model.predict_to_sequence(predictions, samples)\\n        note_seq.note_sequence_to_midi_file(sequence, midi_path)\\n        midi_files.append(midi_path)\\n        \\n    return midi_files\\n\\n#wav_path = downloaded_files\\n#transcribe_wav_to_midi(wav_path)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Converting wav files to midi files\n",
    "CHECKPOINT_PATH = \"../maestro_checkpoint/model.ckpt\"\n",
    "\n",
    "def load_model():\n",
    "    model_config = configs.CONFIG_MAP['onsets_frames']\n",
    "    hparams = model_config.hparams\n",
    "    hparams.use_cudnn = tf.test.is_gpu_available()\n",
    "    return onsets_frames_transcription_transcribe.run(model_config, CHECKPOINT_PATH)\n",
    "\n",
    "\n",
    "def transcribe_wav_to_midi(wav_path):\n",
    "    model = load_model()\n",
    "    midi_files =[]\n",
    "    for index, item in enumerate(wav_path):\n",
    "        midi_path = f'midi_{index}.mid'\n",
    "        \n",
    "        samples = note_seq.audio_io.wav_data_to_samples(item, sample_rate=16000)\n",
    "        input_tensors = data.classify_audio_to_input_tensors(samples, hparams)\n",
    "        predictions = model.predict(input_tensors, input_tensors)\n",
    "        sequence = model.predict_to_sequence(predictions, samples)\n",
    "        note_seq.note_sequence_to_midi_file(sequence, midi_path)\n",
    "        midi_files.append(midi_path)\n",
    "        \n",
    "    return midi_files\n",
    "\n",
    "#wav_path = downloaded_files\n",
    "#transcribe_wav_to_midi(wav_path)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529ffefe-c03d-4641-a92d-607f4bcf39c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af59f78f-4c91-45d8-a32d-18a5469cdaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef merge_midi_files(midi_files, output_file):\\n    #Merge multiple MIDI files into a single MIDI file.\\n    # Initialize an empty NoteSequence\\n    combined_sequence = music_pb2.NoteSequence()\\n    \\n    for midi_file in midi_files:\\n        # Read the MIDI file into a NoteSequence\\n        sequence = mm.midi_file_to_note_sequence(midi_file)\\n        \\n        # Append the notes to the combined sequence\\n        combined_sequence.notes.extend(sequence.notes)\\n        \\n        # Adjust the total time of the combined sequence\\n        combined_sequence.total_time = max(combined_sequence.total_time, sequence.total_time)\\n    \\n    # Convert the NoteSequence back to a MIDI file\\n    mm.sequence_proto_to_midi_file(combined_sequence, output_file)\\n    \\n    print(f\"Merged MIDI file saved as {output_file}\")\\n\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def merge_midi_files(midi_files, output_file):\n",
    "    #Merge multiple MIDI files into a single MIDI file.\n",
    "    # Initialize an empty NoteSequence\n",
    "    combined_sequence = music_pb2.NoteSequence()\n",
    "    \n",
    "    for midi_file in midi_files:\n",
    "        # Read the MIDI file into a NoteSequence\n",
    "        sequence = mm.midi_file_to_note_sequence(midi_file)\n",
    "        \n",
    "        # Append the notes to the combined sequence\n",
    "        combined_sequence.notes.extend(sequence.notes)\n",
    "        \n",
    "        # Adjust the total time of the combined sequence\n",
    "        combined_sequence.total_time = max(combined_sequence.total_time, sequence.total_time)\n",
    "    \n",
    "    # Convert the NoteSequence back to a MIDI file\n",
    "    mm.sequence_proto_to_midi_file(combined_sequence, output_file)\n",
    "    \n",
    "    print(f\"Merged MIDI file saved as {output_file}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b72c9f9-9ed4-4b42-86e7-89d92710d298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
